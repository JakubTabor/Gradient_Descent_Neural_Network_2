# Gradient_Descent_Neural_Network_2
I gonna build neural network from scratch also with gradient descent inside 
# I gonna build some helper functions which i gonna use later in my model
# First I need activation function for my model so I define sigmoid function, It will eturn value in  range 0 to 1
# Now my "prediction_function", so i fill paterrn which is (w1 * x1 + w2 * x2 + bias) I save it as "weighted_sum" and return activation of my "weighted_sum"
# Then I check if my function works good and it seems that everything is alright
# Next I build "log loss" function, in simple words it take values in range 0 to 1, very close to this numbers but not exact numbers
# Then it return mean log loss, so i use "-np.mean" to get mean value and "np.log" to get log of y_predicted_new and log of "1 - y_predicted_new"
# And "y_predicted_new" is first my value close to 0 "[max(i, epsilon) for i in y_predicted]" and the value close to 1 "[min(i, 1 - epsilon) for i in y_predicted_new]"
# I change my activation function into numpy, I look at values that function returns, they are in range 0 to 1
# Now I can build Neural Network, so I start with constructor function, define my weights and bias  
# Next i define fit function, it will train my model, so I call gradient descent function, that I will build in a moment
# Inside it I put "age of X and affordibility of X", then y, then epochs and loss_thresold, all will be return in form of tuple
# loss_thresold define where my function need to stop to, I take the number from my keras model 
# I save it as my weights and bias, I pass this arguments for my gradient descent and it will calculate the output values
# And It will print my weights and bias for comparison to my keras model 
# Then I define predict function, so w1 * x1 + w2 * x2 + bias and in that case i take x1 and x2 from my X_test 
# I save it as weighted_sum and put variable into activation function, so previous defined "sigmoid_numpy" 
# Now its time to define gradient descent, first I initialize my weights with ones and bias with zero
