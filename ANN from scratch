# Gradient_Descent_Neural_Network_2
I gonna build neural network from scratch also with gradient descent inside 
# I gonna build some helper functions which i gonna use later in my model
# First I need activation function for my model so I define sigmoid function, It will eturn value in  range 0 to 1
# Now my "prediction_function", so i fill paterrn which is (w1 * x1 + w2 * x2 + bias) I save it as "weighted_sum" and return activation of my "weighted_sum"
# Then I check if my function works good and it seems that everything is alright
# Next I build "log loss" function, in simple words it take values in range 0 to 1, very close to this numbers but not exact numbers
# Then it return mean log loss, so i use "-np.mean" to get mean value and "np.log" to get log of y_predicted_new and log of "1 - y_predicted_new"
# And "y_predicted_new" is first my value close to 0 "[max(i, epsilon) for i in y_predicted]" and the value close to 1 "[min(i, 1 - epsilon) for i in y_predicted_new]"
# I change my activation function into numpy, I look at values that function returns, they are in range 0 to 1
# Now I can build Neural Network, so I start with constructor function, define my weights and bias  
# Next i define fit function, it will train my model, so I call gradient descent function, that I will build in a moment
